{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-05-15 00:10:31.191723: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2023-05-15 00:10:31.382759: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2023-05-15 00:10:31.384083: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2023-05-15 00:10:32.185188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import music21 as m21\n",
                "import json\n",
                "import tensorflow.keras as keras\n",
                "import numpy as np\n",
                "\n",
                "KERN_DATASET_PATH = \"./deutschl/test\"\n",
                "DATASET_PATH = \"dateset\"\n",
                "SINGLE_FILE_PATH = \"file_dataset\"\n",
                "\n",
                "SEQUENCE_LENGTH = 64\n",
                "MAPPING_PATH = \"mapping.json\"\n",
                "\n",
                "ACCEPTABLE_DURATIONS = [\n",
                "\t0.25,\n",
                "\t0.5,\n",
                "\t1.0,\n",
                "\t1.5,\n",
                "\t2, \n",
                "\t3,\n",
                "\t4\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def load_songs_in_kern(dataset_path):\n",
                "    songs = []\n",
                "    for path, subdirs, files in os.walk(dataset_path):\n",
                "        for file in files:\n",
                "            if file[-3:] == \"krn\":\n",
                "                song = m21.converter.parse(os.path.join(path, file))\n",
                "                songs.append((song, file.split(\".\")[0]))\n",
                "                \n",
                "    return songs\n",
                "\n",
                "def is_acceptable_song(song, acceptable_duration):\n",
                "    # for note in song.flat.notesAndRests:\n",
                "    #     if note.duration.quarterLength not in acceptable_duration:\n",
                "    #         return False\n",
                "        \n",
                "    return True\n",
                "\n",
                "def transpose(song):\n",
                "    # get key from song\n",
                "    parts = song.getElementsByClass(m21.stream.Part)\n",
                "    mearsure_part0 = parts[0].getElementsByClass(m21.stream.Measure)\n",
                "    key = mearsure_part0[0][4]\n",
                "    \n",
                "    # using m21 to estimate key\n",
                "    if not isinstance(key, m21.key.Key):\n",
                "        key = song.analyze(\"key\")\n",
                "        \n",
                "    # get interval for transposition\n",
                "    if key.mode == \"major\":\n",
                "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\"))\n",
                "    elif key.mode == \"minor\":\n",
                "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A\"))\n",
                "        \n",
                "    # reduce all key to C major or A minor to make learning more easy\n",
                "    transposed_song = song.transpose(interval)\n",
                "    \n",
                "    return transposed_song\n",
                "    \n",
                "def encode_song(song, time_step = 0.25):\n",
                "    # p = 60, d = 1.0 -> [60, _, _, _]\n",
                "    \n",
                "    encoded_song = []\n",
                "    for event in song.flat.notesAndRests:\n",
                "        if isinstance(event, m21.note.Note):\n",
                "            symbol = event.pitch.midi\n",
                "        elif isinstance(event, m21.note.Rest):\n",
                "            symbol = \"r\"\n",
                "            \n",
                "        steps = int(event.duration.quarterLength / time_step)\n",
                "        for step in range(steps):\n",
                "            if step == 0:\n",
                "                encoded_song.append(symbol)\n",
                "            else:\n",
                "                encoded_song.append(\"_\")\n",
                "                \n",
                "    # cast encoded song to a str\n",
                "    encoded_song = \" \".join(map(str, encoded_song))            \n",
                "    return encoded_song \n",
                "        \n",
                "\n",
                "def preprocess(dataset_path):\n",
                "    print(f\"Loading songs...\")\n",
                "    songs = load_songs_in_kern(dataset_path)\n",
                "    print(f\"Loaded {len(songs)} songs\")\n",
                "    \n",
                "    for i, song_info in enumerate(songs):\n",
                "        song = song_info[0]\n",
                "        if not is_acceptable_song(song, ACCEPTABLE_DURATIONS):\n",
                "            print(\"not acceptable: \", song_info[1])\n",
                "            continue\n",
                "        \n",
                "        song = transpose(song)\n",
                "        \n",
                "        encoded_song = encode_song(song)\n",
                "        \n",
                "        save_path = os.path.join(DATASET_PATH, song_info[1])\n",
                "        with open(save_path, \"w\") as fp:\n",
                "            fp.write(encoded_song)\n",
                "            \n",
                "def load(file_path):\n",
                "    with open(file_path, \"r\") as fp:\n",
                "        song = fp.read()\n",
                "    return song\n",
                "        \n",
                "\n",
                "def create_single_file_dataset(dataset_path, file_dataset_path):\n",
                "    new_song_delimeter = \"/ \" * SEQUENCE_LENGTH\n",
                "    songs = \"\"\n",
                "    \n",
                "    for path, _, files in os.walk(dataset_path):\n",
                "        for file in files:\n",
                "            file_path = os.path.join(path, file)\n",
                "            song = load(file_path)\n",
                "            \n",
                "            songs = songs + song + \" \" + new_song_delimeter\n",
                "            \n",
                "    songs = songs[: -1]\n",
                "    with open(file_dataset_path, \"w\") as fp:\n",
                "        fp.write(songs)\n",
                "        \n",
                "    return songs\n",
                "\n",
                "def create_mapping(song_str, mapping_path):\n",
                "    mappings = {}\n",
                "    \n",
                "    songs = song_str.split()\n",
                "    \n",
                "    print(len(songs))\n",
                "    vocabulary = list(set(songs))\n",
                "    \n",
                "    for i, symbol in enumerate(vocabulary):\n",
                "        mappings[symbol] = i\n",
                "        \n",
                "    with open(mapping_path, \"w\") as fp:\n",
                "        json.dump(mappings, fp, indent= 4)\n",
                "        \n",
                "def convert_songs_to_int(encoded_songs):\n",
                "    int_symbols = []\n",
                "    \n",
                "    with open(MAPPING_PATH, \"r\") as fp:\n",
                "        mappings = json.load(fp)\n",
                "        \n",
                "    symbols = encoded_songs.split()\n",
                "    \n",
                "    for symbol in symbols:\n",
                "        int_symbols.append(mappings[symbol])\n",
                "        \n",
                "    return int_symbols\n",
                "\n",
                "def generating_training_sequences(sequence_length):\n",
                "    songs = load(SINGLE_FILE_PATH)\n",
                "    int_songs = convert_songs_to_int(songs)\n",
                "    \n",
                "    inputs = []\n",
                "    targets = []\n",
                "    seq_num = len(int_songs) - sequence_length\n",
                "    \n",
                "    for i in range(seq_num):\n",
                "        inputs.append(int_songs[i: i + sequence_length])\n",
                "        targets.append(int_songs[i + sequence_length])\n",
                "        \n",
                "    # encoding with one-hot\n",
                "    # inputs : (seq_num, sequence_length)\n",
                "    # [[0, 1, 2], [1, 1, 2]] -> [[[1, 0, 0], [0, 1, 0], [0, 0, 1]], [[0, 1, 0], [0, 1, 0], [0, 0, 1]]]\n",
                "     \n",
                "    # targets: (seq_num, 1)\n",
                "    vacubulary_size = len(set(int_songs))\n",
                "    inputs = keras.utils.to_categorical(inputs, num_classes = vacubulary_size)\n",
                "    targets = np.array(targets)\n",
                "    \n",
                "    return inputs, targets\n",
                "    \n",
                "    \n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for test\n",
                "# songs = load_songs_in_kern(KERN_DATASET_PATH)\n",
                "# print(f\"Loaded {len(songs)} songs.\")\n",
                "\n",
                "# song_info = songs[0]\n",
                "# song = song_info[0]\n",
                "\n",
                "# print(\"show song: \", song_info[1])\n",
                "# song.show()\n",
                "# song.show('midi')\n",
                "\n",
                "# transposed_song = transpose(song)\n",
                "# transposed_song.show()\n",
                "# transposed_song.show('midi')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading songs...\n",
                        "Loaded 12 songs\n",
                        "2576\n",
                        "(2512, 64, 18)\n",
                        "(2512,)\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# main procedure\n",
                "preprocess(KERN_DATASET_PATH)\n",
                "songs = create_single_file_dataset(DATASET_PATH, SINGLE_FILE_PATH)\n",
                "create_mapping(songs, MAPPING_PATH)\n",
                "\n",
                "inputs, targets = generating_training_sequences(SEQUENCE_LENGTH)\n",
                "\n",
                "print(inputs.shape)\n",
                "print(targets.shape)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
